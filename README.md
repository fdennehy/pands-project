# pands-project

## About This Project

This repository contains a Python program (analysis.py) which explores the well-known Fisher's Iris data set using analytical methods learned as part of the Programming and Scripting module of the [HDip in Science in Computing in Data Analytics](https://www.gmit.ie/higher-diploma-in-science-in-computing-in-data-analytics), ATU Galway. In addition to the Python program, the repository contains a .gitignore file, multiple image (.png) files, two .csv files, a Jupyter Notebook (iris.ipynb) and this README.md file. A brief description of each file is provided under the 'Files Description' section.

## Fisher's Iris Data Set

[Fisher's Iris Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set) is a set of data collected by [Edgar Anderson](https://en.wikipedia.org/wiki/Edgar_Anderson), and subsequently made famous by [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) "in his 1936 paper _The use of multiple measurements in taxonomic problems_ as an example of linear discriminant analysis". The data set contains 150 records of Iris flowers (50 records for each of the three Iris species recorded) and each record has five attributes:
- _Sepal length_
- _Sepal width_
- _Petal length_
- _Petal width_
- _Species_

![iris_species.png](Iris_species.png)
Source: https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nfK3vGZkTa4GrO7yWpcS-Q.png

Due to its simplicity, standardization and versatility, this data set has become popular for testing machine learning techniques, particularly classifaction techniques such as [support vector machines](https://en.wikipedia.org/wiki/Support_vector_machine) and [k-nearest neighbours (KNN)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).

## Files Description

1. **.gitignore**\
_Description_: I have used the below github templates to create my .gitignore file:\
    https://github.com/github/gitignore/blob/main/Python.gitignore \
    https://github.com/github/gitignore/blob/main/Global/Windows.gitignore \
    https://github.com/github/gitignore/blob/main/Global/macOS.gitignore 

2. **analysis.py**\
_Description_: Python program that corresponds to some of the sections of the Iris.ipynb. Contains core code.
- 1. DATA LOAD AND OVERVIEW
- 2. VARIABLE SUMMARY
- 3. VISUALIZATIONS
- 4. CORRELATION
- 5. LOGISTIC REGRESSION

3. **Iris_dist_by_species.png**\
_Description_: Four histograms, one per variable, with specie labless. This image is generated by the code.

4. **Iris_dist.png**\
_Description_: Four histograms, one per variable, without specie lables. This image is generated by the code.

5. **Iris_Scatterplots_2D.png**\
_Description_: Six scatterplots, one per pair of variables, with specie lables visualised in 2-D. This image is generated by the code.

6. **Iris_Scatterplots_3D.png**\
_Description_: Four scatterplots, one per trio of variables, with specie lables visualised in 3-D. This image is generated by the code.

7. **Iris_species.png**\
_Description_: An image to help visualise the different measurements within the data set, used for this README.

8. **Iris.csv**\
_Description_: Local copy of the Iris data set used for this project. This file is generated by the code.

9. **Iris.ipynb**\
_Description_: Jupyter Notebook which adds commentary and reference links to the analysis.py code, with the following sections:
- _Imports_: Packages required for this analysis.
- _Data Load & Overview_: Initial data load and high level overview of this data.
- _Variable Summary_: Summary of the five variables in the Iris data set.
- _Visualizations_: Using appropriate plots (histograms and scatterplots) to visualize different data.
- _Correlation_: Correlation coefficients computed with heatmap to visualize.
- _Machine Learning_: Brief Overview of ML models that can be used after EDA stage.
- _Logistic Regression_: Implementation of Logistic Regression using scikit learning packages.
- _Summary_: Summary of findings

10. **README.md**\
_Description_: This README has been written with [GitHub's documentation on READMEs](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes) in mind.

11. **scikit-learn_ml_map.png**\
_Description_: Copy of the scikit-learn "algorithm cheat sheet", used to embed in the Jupyter Notebook.

12. **variable_summary.csv**\
_Description_: csv file containing seperate customized summaries of the categorcal and numerical values in the Iris data set. This file is generated by the code.

## Use of this Project

This project may be useful to prospective students of the HDip in Science in Computing in Data Analytics course at ATU Galway, giving an indication of the content of the Programming and Scripting moduule and showcasing what can be achieved within three months of the course. It may also be useful to other Python learners beginning their Data Analytics journey.

## Get Started 

You can jump straight to the notebook using the following clickable link, which was generated using [openincolab.com/](https://openincolab.com/)

This opens the `iris.ipynb` notebook in [Google Colab](https://colab.research.google.com/).

<a target="_blank" href="https://colab.research.google.com/github/fdennehy/pands-project/blob/main/iris.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

To run the files locally, clone the repository and then run the python files locally.

### Cloning the Repository

1. Open your terminal or command prompt. (I use [cmder](https://cmder.app/))
2. Navigate to the directory where you want to clone the repository.
3. Use the following command to clone the repository:
```bash
git clone https://github.com/fdennehy/pands-project
```

### Running Python Files

1. After cloning the repository, navigate into the repository's directory through the command prompt:
```bash
cd repository_name
```
Replace <repository_name> with the name of the directory under which you cloned the repository.

2. Once inside the repository's directory, you can run the .py scripts using the Python interpreter. To to run the analysis.py script, use the following command:
```bash
python analysis.py
```

Now you're ready to explore and use the Python files in the repository! 

## Get Help

Read the comments provided within the Jupyter Notebook and look up official Python documentation for further usage guidance.

## Contribute

Developers are welcome to fork this repo and continue to develop and expand upon it as they wish.

## Author

**Finbar Dennehy**

I'm currently undertaking the [HDip in Science in Computing in Data Analytics](https://www.gmit.ie/higher-diploma-in-science-in-computing-in-data-analytics) on a part time basis at [ATU](https://www.atu.ie/)

I have over ten years' experience in capital markets consultancy and have spent the past few years working on software delivery and customer success. I am undertaking this program to better understand our clients, who are predominantly data scientists and data engineers.

## Acknowledgements

Special thanks to my lecturer on the Programming and Scripting module, Andrew Beatty, from whom I acquired the skills necessary to put this project together.
Now I'm going to stand up, strecth and grab myself a cup of tea!